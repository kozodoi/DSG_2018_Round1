{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "data = pd.read_csv(\"../data/prepared/data_basic.csv\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "print(\"Dimensions:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. FUNCTIONS TO CREATE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTION FOR COMPUTING WEEK INDEX\n",
    "def week_idx(date, end_date):\n",
    "    return round((end_date - date).dt.days / 7 + 0.4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RECENCY (TIME SINCE LAST TRADE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION TO COMPUTE 6 RECENCY-BASED FEATURES \n",
    "# 1) Time since last customer trade with that bond with the same BuySell direction\n",
    "# 2) Time since last customer trade with that bond with any direction\n",
    "# 3) Time since last customer trade with any bond with the same BuySell direction\n",
    "# 4) Time since last customer trade with any bond with any direction\n",
    "# 5) Time since last trade with that bond by any of the customers with the same BuySell direction\n",
    "# 6) Time since last trade with that bond by any of the customers\n",
    "\n",
    "def compute_recency(data):\n",
    "\n",
    "    tmp = data[data.CustomerInterest == 1]\n",
    "    \n",
    "    tmp[\"PrevWeek\"] = tmp.sort_values(by = [\"Week\"], ascending = True).groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"]).Week.shift(1)\n",
    "    tmp[\"CurrWeek\"] = tmp.Week\n",
    "\n",
    "    data = data.merge(tmp, how = \"left\")\n",
    "\n",
    "    data[\"CurrWeek\"] = data.groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"]).CurrWeek.fillna(method = \"ffill\")\n",
    "    data[\"PrevWeek\"] = data.groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"]).PrevWeek.fillna(method = \"bfill\")\n",
    "    data[\"PrevWeek\"][data.PrevWeek.isnull()] = data[\"CurrWeek\"]\n",
    "    data[\"PrevWeek\"][data.PrevWeek >= data.Week] = None\n",
    "    \n",
    "    data[\"Recency1\"] = data[\"Week\"] - data[\"PrevWeek\"]\n",
    "    data[\"Recency1\"][data.Recency1 <= 0] = None\n",
    "    del data[\"PrevWeek\"], data[\"CurrWeek\"]\n",
    "\n",
    "    Recency2 = data.groupby([\"CustomerIdx\", \"IsinIdx\", \"Week\"]).Recency1.min().reset_index()\n",
    "    Recency2.columns = [\"CustomerIdx\", \"IsinIdx\", \"Week\", \"Recency2\"]\n",
    "    data = data.merge(Recency2, how = \"left\", on = [\"CustomerIdx\", \"IsinIdx\", \"Week\"])\n",
    "    \n",
    "    Recency3 = data.groupby([\"CustomerIdx\", \"BuySell\", \"Week\"]).Recency1.min().reset_index()\n",
    "    Recency3.columns = [\"CustomerIdx\", \"BuySell\", \"Week\", \"Recency3\"]\n",
    "    data = data.merge(Recency3, how = \"left\", on = [\"CustomerIdx\", \"BuySell\", \"Week\"])\n",
    "    \n",
    "    Recency4 = data.groupby([\"CustomerIdx\", \"Week\"]).Recency1.min().reset_index()\n",
    "    Recency4.columns = [\"CustomerIdx\", \"Week\", \"Recency4\"]\n",
    "    data = data.merge(Recency4, how = \"left\", on = [\"CustomerIdx\", \"Week\"])\n",
    "    \n",
    "    Recency5 = data.groupby([\"IsinIdx\", \"BuySell\", \"Week\"]).Recency1.min().reset_index()\n",
    "    Recency5.columns = [\"IsinIdx\", \"BuySell\", \"Week\", \"Recency5\"]\n",
    "    data = data.merge(Recency5, how = \"left\", on = [\"IsinIdx\", \"BuySell\", \"Week\"])\n",
    "    \n",
    "    Recency6 = data.groupby([\"IsinIdx\", \"Week\"]).Recency1.min().reset_index()\n",
    "    Recency6.columns = [\"IsinIdx\", \"Week\", \"Recency6\"]\n",
    "    data = data.merge(Recency6, how = \"left\", on = [\"IsinIdx\", \"Week\"])\n",
    "    \n",
    "    data.Recency1.fillna(data.Recency1.max(), inplace = True)\n",
    "    data.Recency2.fillna(data.Recency2.max(), inplace = True)\n",
    "    data.Recency3.fillna(data.Recency3.max(), inplace = True)\n",
    "    data.Recency4.fillna(data.Recency4.max(), inplace = True)\n",
    "    data.Recency5.fillna(data.Recency5.max(), inplace = True)\n",
    "    data.Recency6.fillna(data.Recency6.max(), inplace = True)\n",
    "    \n",
    "    data[\"Recency1isLowerRecency2\"] = 0\n",
    "    data[\"Recency1isLowerRecency2\"][data.Recency1 <= data.Recency2] = 1\n",
    "    \n",
    "    data[\"Recency2isLowerRecency4\"] = 0\n",
    "    data[\"Recency2isLowerRecency4\"][data.Recency2 <= data.Recency4] = 1\n",
    "    \n",
    "    print(\"Computed 8 recency features...\")\n",
    "    \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FREQUENCY (TOTAL NUMBER OF TRADES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION TO COMPUTE 6 FREQUENCY-BASED FEATURES \n",
    "# 1) Number of previous customer trades with that bond with the same BuySell direction\n",
    "# 2) Number of previous customer trades with that bond with any direction\n",
    "# 3) Number of previous customer trades with any bond with the same BuySell direction\n",
    "# 4) Number of previous customer trades with any bond with any direction\n",
    "# 5) Number of previous trades with that bond by any of the same BuySell direction\n",
    "# 6) Number of previous trades with that bond by any of the customers\n",
    "# all frequencies are divided by the number of weeks during which they were observed\n",
    "\n",
    "def compute_frequency(data):\n",
    "\n",
    "    tmp = data[data.CustomerInterest == 1]\n",
    "\n",
    "    tmp[\"Frequency1\"] = tmp.sort_values(by = [\"Week\"], ascending = True).groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"]).CustomerInterest.cumsum()\n",
    "\n",
    "    data = data.merge(tmp, how = \"left\")\n",
    "    data[\"Frequency1\"] = data.groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"]).Frequency1.fillna(method = \"ffill\")\n",
    "    data[\"Frequency1\"][data[\"CustomerInterest\"] == 1] = data[\"Frequency1\"][data[\"CustomerInterest\"] == 1] - 1\n",
    "    data[\"Frequency1\"].fillna(0, inplace = True)\n",
    "\n",
    "    Frequency2 = data.groupby([\"CustomerIdx\", \"IsinIdx\", \"Week\"]).Frequency1.sum().reset_index()\n",
    "    Frequency2.columns = [\"CustomerIdx\", \"IsinIdx\", \"Week\", \"Frequency2\"]\n",
    "    data = data.merge(Frequency2, how = \"left\", on = [\"CustomerIdx\", \"IsinIdx\", \"Week\"])\n",
    "    \n",
    "    Frequency3 = data.groupby([\"CustomerIdx\", \"BuySell\", \"Week\"]).Frequency1.sum().reset_index()\n",
    "    Frequency3.columns = [\"CustomerIdx\", \"BuySell\", \"Week\", \"Frequency3\"]\n",
    "    data = data.merge(Frequency3, how = \"left\", on = [\"CustomerIdx\", \"BuySell\", \"Week\"])\n",
    "\n",
    "    Frequency4 = data.groupby([\"CustomerIdx\", \"Week\"]).Frequency1.sum().reset_index()\n",
    "    Frequency4.columns = [\"CustomerIdx\", \"Week\", \"Frequency4\"]\n",
    "    data = data.merge(Frequency4, how = \"left\", on = [\"CustomerIdx\", \"Week\"])\n",
    "\n",
    "    Frequency5 = data.groupby([\"IsinIdx\", \"Week\", \"BuySell\"]).Frequency1.sum().reset_index()\n",
    "    Frequency5.columns = [\"IsinIdx\", \"Week\", \"BuySell\", \"Frequency5\"]\n",
    "    data = data.merge(Frequency5, how = \"left\", on = [\"IsinIdx\", \"Week\", \"BuySell\"])\n",
    "    \n",
    "    Frequency6 = data.groupby([\"IsinIdx\", \"Week\"]).Frequency1.sum().reset_index()\n",
    "    Frequency6.columns = [\"IsinIdx\", \"Week\", \"Frequency6\"]\n",
    "    data = data.merge(Frequency6, how = \"left\", on = [\"IsinIdx\", \"Week\"])\n",
    "    \n",
    "    data[\"Frequecny1isLowerFrequency2\"] = 0\n",
    "    data[\"Frequecny1isLowerFrequency2\"][data.Frequency1 < data.Frequency2] = 1\n",
    "    \n",
    "    data[\"Frequecny2isLowerFrequency4\"] = 0\n",
    "    data[\"Frequecny2isLowerFrequency4\"][data.Frequency2 < data.Frequency4] = 1\n",
    "    \n",
    "    div = data.Week - data.Week.min()\n",
    "    div[div == 0] = 1\n",
    "    for var in [\"Frequency1\", \"Frequency2\", \"Frequency3\", \"Frequency4\", \"Frequency5\", \"Frequency6\"]:\n",
    "        data[var] = data[var] / div\n",
    "    \n",
    "    print(\"Computed 8 frequency features...\")\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MONTH ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION TO COMPUTE MONTH\n",
    "# 1) Month of each trade\n",
    "\n",
    "def compute_month(data):\n",
    "\n",
    "    tmp = pd.read_csv(\"../data/raw/Trade.csv\")\n",
    "    tmp = tmp[[\"TradeDateKey\"]]\n",
    "\n",
    "    ### FUNCTION FOR COMPUTING WEEK INDEX\n",
    "    def week_idx(date, end_date):\n",
    "        return round((end_date - date).dt.days / 7 + 0.4).astype(int)\n",
    "\n",
    "    tmp[\"TradeDateKey\"] = pd.to_datetime(tmp[\"TradeDateKey\"], format = '%Y%m%d')\n",
    "    tmp[\"Week\"] = week_idx(tmp[\"TradeDateKey\"], pd.Timestamp('2018-04-23 00:00:00'))\n",
    "    tmp[\"Month\"] = tmp[\"TradeDateKey\"].dt.month.astype(\"object\")\n",
    "    del tmp[\"TradeDateKey\"]\n",
    "    tmp = tmp.drop_duplicates()\n",
    "\n",
    "    data = data.merge(tmp, how = \"left\", on = \"Week\")\n",
    "    data[\"Month\"][data.Week == 121] = \"4\"\n",
    "    \n",
    "    print(\"Computed 1 month feature...\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. COMPUTING FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute past features\n",
    "data = compute_recency(data)\n",
    "data = compute_frequency(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute months\n",
    "data = compute_month(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. CORRECT AND EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check recency distribution\n",
    "data.Recency1.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del bond_stat, macro_diff1, fx_diff1, bond, bond_dummies, cust_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first X weeks\n",
    "data = data[data.Week > 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA\n",
    "nas = data.isnull().sum()\n",
    "nas[nas > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CSV\n",
    "data.to_csv(\"../data/prepared/data_v4_0_60_under.csv\", index = False, compression = \"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
