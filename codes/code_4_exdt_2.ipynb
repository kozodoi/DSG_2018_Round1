{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import spearmanr\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data name (used for saving files too)\n",
    "data_name = \"data_v4_0_60_under\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "data = pd.read_csv(\"../data/prepared/\" + str(data_name) + \".csv\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data name (used for saving files too)\n",
    "data_name = \"data_v4_0_60_under_wlp_lm_bm_mff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop high recency from train\n",
    "data = data[(data.Week == 121) | (data.Recency1 < data.Recency1.max())]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PREPARATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADD MORE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute BuySell dummy\n",
    "data[\"Buy\"] = 0\n",
    "data[\"Buy\"][data.BuySell == \"Buy\"] = 1\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add last week sum (CUST)\n",
    "tmp = data.sort_values(by = [\"Week\"], ascending = True).groupby([\"CustomerIdx\", \"Week\"], as_index = True)\n",
    "tmp = tmp.CustomerInterest.sum().reset_index()\n",
    "tmp.columns = [\"CustomerIdx\", \"Week\", \"LastWeekCustSum\"]\n",
    "tmp[\"Week\"] = tmp.Week + 1\n",
    "data = data.merge(tmp, how = \"left\", on = [\"CustomerIdx\", \"Week\"])\n",
    "print(data.shape)\n",
    "\n",
    "# add last week sum (BOND)\n",
    "tmp = data.sort_values(by = [\"Week\"], ascending = True).groupby([\"IsinIdx\", \"Week\"], as_index = True)\n",
    "tmp = tmp.CustomerInterest.sum().reset_index()\n",
    "tmp.columns = [\"IsinIdx\", \"Week\", \"LastWeekBondSum\"]\n",
    "tmp[\"Week\"] = tmp.Week + 1\n",
    "data = data.merge(tmp, how = \"left\", on = [\"IsinIdx\", \"Week\"])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD PRICE AND NOTIONAL\n",
    "\n",
    "tmp = pd.read_csv(\"../data/prepared/price_notional.csv\", compression = \"gzip\")\n",
    "\n",
    "# add last week price sum (CUST)\n",
    "tmp2 = tmp.sort_values(by = [\"Week\"], ascending = True).groupby([\"CustomerIdx\", \"Week\"], as_index = True)\n",
    "tmp2 = tmp2.Price.sum().reset_index()\n",
    "tmp2.columns = [\"CustomerIdx\", \"Week\", \"LastWeekCustPriceSum\"]\n",
    "tmp2[\"Week\"] = tmp2.Week + 1\n",
    "data = data.merge(tmp2, how = \"left\", on = [\"CustomerIdx\", \"Week\"])\n",
    "print(data.shape)\n",
    "\n",
    "# add last week notional sum (CUST)\n",
    "tmp2 = tmp.sort_values(by = [\"Week\"], ascending = True).groupby([\"CustomerIdx\", \"Week\"], as_index = True)\n",
    "tmp2 = tmp2.NotionalEUR.sum().reset_index()\n",
    "tmp2.columns = [\"CustomerIdx\", \"Week\", \"LastWeekCustNotionalSum\"]\n",
    "tmp2[\"Week\"] = tmp2.Week + 1\n",
    "data = data.merge(tmp2, how = \"left\", on = [\"CustomerIdx\", \"Week\"])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD LAST MONTH SUMS\n",
    "\n",
    "# merge month number\n",
    "tmp = pd.read_csv(\"../data/raw/Trade.csv\")[[\"TradeDateKey\"]]\n",
    "tmp = tmp.drop_duplicates()\n",
    "tmp[\"TradeDateKey\"] = pd.to_datetime(tmp[\"TradeDateKey\"], format = '%Y%m%d')\n",
    "tmp[\"Week\"] = (tmp.TradeDateKey.dt.year - 2016) * 52 + (tmp.TradeDateKey.dt.week)\n",
    "tmp[\"CumMonth\"] = (tmp.TradeDateKey.dt.year - 2016) * 12 + (tmp.TradeDateKey.dt.month)\n",
    "tmp = tmp[[\"Week\", \"CumMonth\"]]\n",
    "tmp = tmp.drop_duplicates()\n",
    "tmp = tmp.groupby(\"Week\").CumMonth.min().reset_index()\n",
    "data = data.merge(tmp, how = \"left\", on = \"Week\")\n",
    "data[\"CumMonth\"][data.Week == 121] = 28\n",
    "\n",
    "# add last month mean (CUST)\n",
    "tmp = data.sort_values(by = [\"CumMonth\"], ascending = True).groupby([\"CustomerIdx\", \"CumMonth\"], as_index = True)\n",
    "tmp = tmp.CustomerInterest.sum().reset_index()\n",
    "tmp.columns = [\"CustomerIdx\", \"CumMonth\", \"LastMonthCustSum\"]\n",
    "tmp[\"CumMonth\"] = tmp.CumMonth + 1\n",
    "data = data.merge(tmp, how = \"left\", on = [\"CustomerIdx\", \"CumMonth\"])\n",
    "print(data.shape)\n",
    "\n",
    "# add last month mean (BOND)\n",
    "tmp = data.sort_values(by = [\"CumMonth\"], ascending = True).groupby([\"IsinIdx\", \"CumMonth\"], as_index = True)\n",
    "tmp = tmp.CustomerInterest.sum().reset_index()\n",
    "tmp.columns = [\"IsinIdx\", \"CumMonth\", \"LastMonthBondSum\"]\n",
    "tmp[\"CumMonth\"] = tmp.CumMonth + 1\n",
    "data = data.merge(tmp, how = \"left\", on = [\"IsinIdx\", \"CumMonth\"])\n",
    "print(data.shape)\n",
    "\n",
    "# drop month\n",
    "del data[\"CumMonth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD BOND MATURITY DATA\n",
    "\n",
    "# import\n",
    "bond = pd.read_csv(\"../data/prepared/data_bond_v1.csv\", compression = \"gzip\")\n",
    "bond = bond[['IsinIdx', 'MaturityWeek', 'IssueWeek']]\n",
    "\n",
    "# merge\n",
    "data = data.merge(bond, on = \"IsinIdx\", how = \"left\")\n",
    "\n",
    "# compute week differences\n",
    "data[\"MaturityWeek\"]    = data.MaturityWeek - data.Week\n",
    "data[\"IssueWeek\"]       = data.Week - data.IssueWeek\n",
    "data[\"MaturityPercent\"] = (data.Week - data.IssueWeek) / (data.MaturityWeek - data.IssueWeek)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FAVORITE FEATURES\n",
    "\n",
    "bond  = pd.read_csv(\"../data/raw/Isin.csv\")\n",
    "bond.loc[~bond.Seniority.isin([\"GOV\",\"SEC\",\"SEN\",\"SUB\"]), \"Seniority\"] = \"OTHER\"\n",
    "bond.loc[~bond.Activity.isin([\"Asia\",\"RETAIL\",\"GBP SAS\", \"ARGENTINIA\"]), \"Activity\"] = \"OTHER\"\n",
    "bond.loc[bond.Currency.isin(\n",
    "    (bond.groupby(\"Currency\").size())[bond.groupby(\"Currency\").size()<350].index.tolist()\n",
    "), \"Currency\"] = \"OTHER\"\n",
    "\n",
    "bond.loc[bond.CompositeRating.str.contains(\"C|D\"), \"CompositeRating\"] = \"LOWER\"\n",
    "# Risk captain\n",
    "bond.loc[bond.RiskCaptain.isin(\n",
    "    (bond.groupby(\"RiskCaptain\").size())[bond.groupby(\"RiskCaptain\").size()<200].index.tolist()\n",
    "), \"RiskCaptain\"] = \"OTHER\"\n",
    "\n",
    "bond = bond[[\n",
    "       'IsinIdx', \"TickerIdx\",\n",
    "       'Seniority', 'Currency', 'ActivityGroup', 'Region', 'Activity',\n",
    "       'RiskCaptain', 'Owner', 'CompositeRating', 'IndustrySector',\n",
    "       'IndustrySubgroup', 'MarketIssue', 'CouponType']]\n",
    "\n",
    "favor = pd.read_csv(\"../data/prepared/favorite_bonds_v3_60.csv\", compression = \"gzip\")\n",
    "\n",
    "data = data.merge(bond,  how = \"left\")\n",
    "data = data.merge(favor, how = \"left\")\n",
    "\n",
    "data[\"BuySell_mode\"][data.BuySell == data[\"BuySell_mode\"]] = 1\n",
    "data[\"BuySell_mode\"][data.BuySell_mode != 1] = 0\n",
    "\n",
    "data[\"TickerIdx_mode\"][data.TickerIdx == data[\"TickerIdx_mode\"]] = 1\n",
    "data[\"TickerIdx_mode\"][data.TickerIdx != 1] = 0\n",
    "\n",
    "data[\"IsinIdx_mode\"][data.IsinIdx == data[\"IsinIdx_mode\"]] = 1\n",
    "data[\"IsinIdx_mode\"][data.IsinIdx_mode != 1] = 0\n",
    "\n",
    "data[\"Seniority_mode\"][data.Seniority == data[\"Seniority_mode\"]] = 1\n",
    "data[\"Seniority_mode\"][data.Seniority_mode != 1] = 0\n",
    "\n",
    "data[\"Currency_mode\"][data.Currency == data[\"Currency_mode\"]] = 1\n",
    "data[\"Currency_mode\"][data.Currency_mode != 1] = 0\n",
    "\n",
    "data[\"ActivityGroup_mode\"][data.ActivityGroup == data[\"ActivityGroup_mode\"]] = 1\n",
    "data[\"ActivityGroup_mode\"][data.ActivityGroup_mode != 1] = 0\n",
    "\n",
    "data[\"Region_mode\"][data.Region == data[\"Region_mode\"]] = 1\n",
    "data[\"Region_mode\"][data.Region_mode != 1] = 0\n",
    "\n",
    "data[\"Activity_mode\"][data.Activity == data[\"Activity_mode\"]] = 1\n",
    "data[\"Activity_mode\"][data.Activity_mode != 1] = 0\n",
    "\n",
    "data[\"RiskCaptain_mode\"][data.RiskCaptain == data[\"RiskCaptain_mode\"]] = 1\n",
    "data[\"RiskCaptain_mode\"][data.RiskCaptain_mode != 1] = 0\n",
    "\n",
    "data[\"Owner_mode\"][data.Owner == data[\"Owner_mode\"]] = 1\n",
    "data[\"Owner_mode\"][data.Owner_mode != 1] = 0\n",
    "\n",
    "data[\"CompositeRating_mode\"][data.CompositeRating == data[\"CompositeRating_mode\"]] = 1\n",
    "data[\"CompositeRating_mode\"][data.CompositeRating_mode != 1] = 0\n",
    "\n",
    "data[\"IndustrySector_mode\"][data.IndustrySector == data[\"IndustrySector_mode\"]] = 1\n",
    "data[\"IndustrySector_mode\"][data.IndustrySector != 1] = 0\n",
    "\n",
    "data[\"IndustrySubgroup_mode\"][data.IndustrySubgroup == data[\"IndustrySubgroup_mode\"]] = 1\n",
    "data[\"IndustrySubgroup_mode\"][data.IndustrySubgroup != 1] = 0\n",
    "\n",
    "data[\"MarketIssue_mode\"][data.MarketIssue == data[\"MarketIssue_mode\"]] = 1\n",
    "data[\"MarketIssue_mode\"][data.MarketIssue != 1] = 0\n",
    "\n",
    "data[\"CouponType_mode\"][data.CouponType == data[\"CouponType_mode\"]] = 1\n",
    "data[\"CouponType_mode\"][data.CouponType_mode != 1] = 0\n",
    "\n",
    "excluded_features = ['Seniority', 'Currency', 'ActivityGroup', 'Region', 'Activity',\n",
    "       'RiskCaptain', 'Owner', 'CompositeRating', 'IndustrySector',\n",
    "       'IndustrySubgroup', 'MarketIssue', 'CouponType', \"TickerIdx\"]\n",
    "features = [var for var in data.columns if var not in excluded_features]\n",
    "data = data[features]\n",
    "\n",
    "modes = list(data.filter(like = \"_mode\").columns)\n",
    "for var in modes:\n",
    "    data[var] = data[var].astype(int)\n",
    "    \n",
    "data[\"NumFavorites\"] = data.filter(like = \"_mode\").sum(axis = 1)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECKS AND PREPARATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "print(\"Dimensions:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA\n",
    "nas = data.isnull().sum()\n",
    "nas[nas > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_with_na = ['MeanPrice', 'StdPrice',\n",
    "       'MeanYield', 'StdYield', 'MeanZScore', 'StdZScore', 'YieldMarktDelta',\n",
    "       'ZScoreMarktDelta']\n",
    "col_zero =  ['LastWeekCustSum', 'LastWeekBondSum',\n",
    "       'LastWeekCustPriceSum', 'LastWeekCustNotionalSum', 'LastMonthCustSum',\n",
    "       'LastMonthBondSum', 'MaturityPercent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_with_na:\n",
    "    data[col].fillna(np.mean(data[col]), inplace=True)\n",
    "    \n",
    "for col in col_zero:\n",
    "    data[col].fillna(np.mean(data[col]), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "excluded_features = [\"PredictionIdx\", \"CustomerIdx\", \"IsinIdx\", \"BuySell\", \"CustomerInterest\",\n",
    "                     \"Frequecny1isLowerFrequency2\", \"Frequecny2isLowerFrequency4\"]\n",
    "features = [var for var in data.columns if var not in excluded_features]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA PARTITIONING\n",
    "\n",
    "# training\n",
    "X_train = data.loc[data.Week < 120]\n",
    "y_train = data.loc[data.Week < 120].CustomerInterest\n",
    "\n",
    "# validation\n",
    "X_valid = data.loc[data.Week == 120]\n",
    "y_valid = data.loc[data.Week == 120].CustomerInterest\n",
    "\n",
    "# test set\n",
    "test = data.loc[data.Week == 121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UPDATE FAVORITE FEATURES FOR TEST DATA\n",
    "\n",
    "test = test.drop(list(test.filter(like = \"_mode\").columns), axis = 1)\n",
    "del test[\"NumFavorites\"]\n",
    "\n",
    "bond  = pd.read_csv(\"../data/raw/Isin.csv\")\n",
    "bond.loc[~bond.Seniority.isin([\"GOV\",\"SEC\",\"SEN\",\"SUB\"]), \"Seniority\"] = \"OTHER\"\n",
    "bond.loc[~bond.Activity.isin([\"Asia\",\"RETAIL\",\"GBP SAS\", \"ARGENTINIA\"]), \"Activity\"] = \"OTHER\"\n",
    "bond.loc[bond.Currency.isin(\n",
    "    (bond.groupby(\"Currency\").size())[bond.groupby(\"Currency\").size()<350].index.tolist()\n",
    "), \"Currency\"] = \"OTHER\"\n",
    "\n",
    "bond.loc[bond.CompositeRating.str.contains(\"C|D\"), \"CompositeRating\"] = \"LOWER\"\n",
    "# Risk captain\n",
    "bond.loc[bond.RiskCaptain.isin(\n",
    "    (bond.groupby(\"RiskCaptain\").size())[bond.groupby(\"RiskCaptain\").size()<200].index.tolist()\n",
    "), \"RiskCaptain\"] = \"OTHER\"\n",
    "\n",
    "bond = bond[[\n",
    "       'IsinIdx', \"TickerIdx\",\n",
    "       'Seniority', 'Currency', 'ActivityGroup', 'Region', 'Activity',\n",
    "       'RiskCaptain', 'Owner', 'CompositeRating', 'IndustrySector',\n",
    "       'IndustrySubgroup', 'MarketIssue', 'CouponType']]\n",
    "\n",
    "tmp = data.loc[data.CustomerInterest == 1]\n",
    "tmp = tmp.loc[tmp.Week < 121]\n",
    "full = tmp.merge(bond, on = [\"IsinIdx\"], how = \"left\")\n",
    "\n",
    "for var in full.columns:\n",
    "    full[var].fillna(\"Other\", inplace = True)\n",
    "\n",
    "import scipy.stats\n",
    "favor = full[[\"CustomerIdx\", \"IsinIdx\", \"TickerIdx\", \"BuySell\", \n",
    "                 'Seniority', 'Currency', 'ActivityGroup', 'Region',\n",
    "                 'Activity', 'RiskCaptain', 'Owner', 'CompositeRating', 'IndustrySector',\n",
    "                 'IndustrySubgroup', 'MarketIssue', 'CouponType']].groupby(\"CustomerIdx\").agg(lambda x: scipy.stats.mode(x)[0][0])\n",
    "favor.columns = favor.columns + \"_mode\"\n",
    "favor = favor.reset_index()\n",
    "\n",
    "### FAVORITE FEATURES\n",
    "\n",
    "test = test.merge(bond,  how = \"left\")\n",
    "test = test.merge(favor, how = \"left\")\n",
    "\n",
    "test[\"BuySell_mode\"][test.BuySell == test[\"BuySell_mode\"]] = 1\n",
    "test[\"BuySell_mode\"][test.BuySell_mode != 1] = 0\n",
    "\n",
    "test[\"TickerIdx_mode\"][test.TickerIdx == test[\"TickerIdx_mode\"]] = 1\n",
    "test[\"TickerIdx_mode\"][test.TickerIdx != 1] = 0\n",
    "\n",
    "test[\"IsinIdx_mode\"][test.IsinIdx == test[\"IsinIdx_mode\"]] = 1\n",
    "test[\"IsinIdx_mode\"][test.IsinIdx_mode != 1] = 0\n",
    "\n",
    "test[\"Seniority_mode\"][test.Seniority == test[\"Seniority_mode\"]] = 1\n",
    "test[\"Seniority_mode\"][test.Seniority_mode != 1] = 0\n",
    "\n",
    "test[\"Currency_mode\"][test.Currency == test[\"Currency_mode\"]] = 1\n",
    "test[\"Currency_mode\"][test.Currency_mode != 1] = 0\n",
    "\n",
    "test[\"ActivityGroup_mode\"][test.ActivityGroup == test[\"ActivityGroup_mode\"]] = 1\n",
    "test[\"ActivityGroup_mode\"][test.ActivityGroup_mode != 1] = 0\n",
    "\n",
    "test[\"Region_mode\"][test.Region == test[\"Region_mode\"]] = 1\n",
    "test[\"Region_mode\"][test.Region_mode != 1] = 0\n",
    "\n",
    "test[\"Activity_mode\"][test.Activity == test[\"Activity_mode\"]] = 1\n",
    "test[\"Activity_mode\"][test.Activity_mode != 1] = 0\n",
    "\n",
    "test[\"RiskCaptain_mode\"][test.RiskCaptain == test[\"RiskCaptain_mode\"]] = 1\n",
    "test[\"RiskCaptain_mode\"][test.RiskCaptain_mode != 1] = 0\n",
    "\n",
    "test[\"Owner_mode\"][test.Owner == test[\"Owner_mode\"]] = 1\n",
    "test[\"Owner_mode\"][test.Owner_mode != 1] = 0\n",
    "\n",
    "test[\"CompositeRating_mode\"][test.CompositeRating == test[\"CompositeRating_mode\"]] = 1\n",
    "test[\"CompositeRating_mode\"][test.CompositeRating_mode != 1] = 0\n",
    "\n",
    "test[\"IndustrySector_mode\"][test.IndustrySector == test[\"IndustrySector_mode\"]] = 1\n",
    "test[\"IndustrySector_mode\"][test.IndustrySector != 1] = 0\n",
    "\n",
    "test[\"IndustrySubgroup_mode\"][test.IndustrySubgroup == test[\"IndustrySubgroup_mode\"]] = 1\n",
    "test[\"IndustrySubgroup_mode\"][test.IndustrySubgroup != 1] = 0\n",
    "\n",
    "test[\"MarketIssue_mode\"][test.MarketIssue == test[\"MarketIssue_mode\"]] = 1\n",
    "test[\"MarketIssue_mode\"][test.MarketIssue != 1] = 0\n",
    "\n",
    "test[\"CouponType_mode\"][test.CouponType == test[\"CouponType_mode\"]] = 1\n",
    "test[\"CouponType_mode\"][test.CouponType_mode != 1] = 0\n",
    "\n",
    "excluded_features = ['Seniority', 'Currency', 'ActivityGroup', 'Region', 'Activity',\n",
    "       'RiskCaptain', 'Owner', 'CompositeRating', 'IndustrySector',\n",
    "       'IndustrySubgroup', 'MarketIssue', 'CouponType', \"TickerIdx\"]\n",
    "feats = [var for var in test.columns if var not in excluded_features]\n",
    "test = test[feats]\n",
    "\n",
    "modes = list(test.filter(like = \"_mode\").columns)\n",
    "for var in modes:\n",
    "    test[var] = test[var].astype(int)\n",
    "    \n",
    "test[\"NumFavorites\"] = test.filter(like = \"_mode\").sum(axis = 1)\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA in test\n",
    "nas = test.isnull().sum()\n",
    "nas[nas > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas = X_valid.isnull().sum()\n",
    "nas[nas > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MODELING - STAGE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters=3000\n",
    "nj = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(n_estimators=num_iters, n_jobs=nj, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PREDICTION\n",
    "\n",
    "### VALID DATA\n",
    "\n",
    "# predict validation set\n",
    "pred_valid = X_valid[[\"CustomerIdx\", \"IsinIdx\", \"BuySell\", \"Week\", \"CustomerInterest\"]]\n",
    "pred_valid[\"TARGET\"] = rf.predict_proba(X_valid[features])[:,1]\n",
    "auc = roc_auc_score(y_valid, pred_valid.TARGET)\n",
    "\n",
    "# export CSV\n",
    "pred_valid.to_csv(\"../pred_valid/auc\" + str(round(auc, 6))[2:8] + \"_\" + str(data_name) + \"_exdt.csv\", \n",
    "                  index = False, float_format = \"%.8f\")\n",
    "\n",
    "\n",
    "### TEST DATA\n",
    "\n",
    "# predict test set\n",
    "test[\"TARGET\"] = rf.predict_proba(test[features])[:,1]\n",
    "\n",
    "# export CSV\n",
    "subm = test[[\"PredictionIdx\", \"TARGET\"]]\n",
    "subm.columns = [\"PredictionIdx\", \"CustomerInterest\"]\n",
    "subm.to_csv(\"../submissions/auc\" + str(round(auc, 6))[2:8] + \"_\" + str(data_name) + \"_exdt_1stage.csv\", \n",
    "            index = False, float_format = \"%.8f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODELING - STAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use full data as train\n",
    "X_train = data.loc[data.Week <= 120]\n",
    "y_train = data.loc[data.Week <= 120].CustomerInterest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(n_estimators=num_iters,  max_depth=None, min_samples_leaf=2, max_features='auto', n_jobs=nj, verbose=1)\n",
    "rf.fit(X_train[features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "test = data.loc[data.Week == 121]\n",
    "# predict test set\n",
    "test[\"TARGET\"] = rf.predict_proba(test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CSV\n",
    "subm = test[[\"PredictionIdx\", \"TARGET\"]]\n",
    "subm.columns = [\"PredictionIdx\", \"CustomerInterest\"]\n",
    "subm.to_csv(\"../submissions/auc\" + str(round(auc, 6))[2:8] + \"_\" + str(data_name) + \"_exdt_2stage.csv\", \n",
    "            index = False, float_format = \"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
