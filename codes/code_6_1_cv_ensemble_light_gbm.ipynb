{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import scipy.stats\n",
    "import os\n",
    "from functions.smooth_stat import smooth_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PARTITIONING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(\"../data/raw/Trade.csv\")\n",
    "test  = pd.read_csv(\"../data/raw/Challenge_20180423.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable\n",
    "train[\"CustomerInterest\"] = 1\n",
    "train[\"CustomerInterest\"][train[\"TradeStatus\"] == \"Holding\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "d_train = train[(train[\"TradeDateKey\"] >=  20170323) & (train[\"TradeDateKey\"] < 20180323)]\n",
    "d_valid = train[(train[\"TradeDateKey\"] >=  20180323)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS-VALIDATION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# learner settings\n",
    "metric   = \"auc\"\n",
    "verbose  = 10\n",
    "stopping = 30\n",
    "seed = 42\n",
    "features = ['cust_int_mean0', 'cust_int_min0', 'cust_int_std0']\n",
    "n_folds = 5\n",
    "\n",
    "# lgb settings\n",
    "gbm = lgb.LGBMClassifier(n_estimators     = 1000,\n",
    "                         learning_rate    = 0.005,\n",
    "                         num_leaves       = 70,\n",
    "                         colsample_bytree = 0.8,\n",
    "                         subsample        = 0.9,\n",
    "                         max_depth        = 7,\n",
    "                         reg_alpha        = 0.1,\n",
    "                         reg_lambda       = 0.1,\n",
    "                         min_split_gain   = 0.01,\n",
    "                         min_child_weight = 2,\n",
    "                         random_state     = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_model(model, train_x, train_y, val_x, val_y):\n",
    "    #create features inside the CV\n",
    "    \n",
    "    # train lightGBM\n",
    "    global verbose\n",
    "    global stopping\n",
    "    global metric\n",
    "    model = model.fit(train_x, train_y, \n",
    "              eval_set = [(train_x, train_y), (val_x, val_y)], \n",
    "              eval_metric = metric, \n",
    "              verbose = verbose, \n",
    "              early_stopping_rounds = stopping)\n",
    "    \n",
    "    # save number of iterations\n",
    "    num_iters = gbm.best_iteration_\n",
    "    best_auc = gbm.best_score_\n",
    "    return (model, num_iters, best_auc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(dataset, validation_set, fold_count, model):\n",
    "    ''' Please, use Xs and y_s sorted by date,\n",
    "    otherwise it can overfitting by looking in the future'''\n",
    "    fold_size = len(dataset) // fold_count\n",
    "    models = {}\n",
    "    epochs = {}\n",
    "    aucs = {}\n",
    "    feat = {}\n",
    "    for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "            if fold_id == fold_size - 1:\n",
    "                fold_end = len(dataset)\n",
    "                \n",
    "            train_data = pd.concat([dataset.iloc[:fold_start,:], dataset.iloc[fold_end:,:]])\n",
    "            val_data = validation_set\n",
    "            #val_data = dataset.iloc[fold_start:fold_end,:]\n",
    "           # train_x = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "           # train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "           # val_x = X[fold_start:fold_end]\n",
    "           # val_y = y[fold_start:fold_end]\n",
    "\n",
    "            # FEATURE CREATION GOES HERE\n",
    "            # Example (in general can be imporved)\n",
    "\n",
    "            # compute historical target ratio\n",
    "            from functions.smooth_stat import smooth_stat\n",
    "            \n",
    "            # \"CustomerIdx\"\n",
    "            target_feature='CustomerInterest'\n",
    "            cust_int_mean0 = smooth_stat(train_data, [\"CustomerIdx\"], type_of_stat='mean',\n",
    "                                        target_feature='CustomerInterest', alpha=10)\n",
    "            cust_int_mean0.rename(columns={f'{target_feature}': 'cust_int_mean0'}, inplace=True)\n",
    "            \n",
    "            cust_int_min0 = smooth_stat(train_data, [\"CustomerIdx\"], type_of_stat='min',\n",
    "                                        target_feature='CustomerInterest', alpha=10)\n",
    "            cust_int_min0.rename(columns={f'{target_feature}': 'cust_int_min0'}, inplace=True)\n",
    "            \n",
    "            cust_int_max0 = smooth_stat(train_data, [\"CustomerIdx\"], type_of_stat='max',\n",
    "                                        target_feature='CustomerInterest', alpha=10)\n",
    "            cust_int_max0.rename(columns={f'{target_feature}': 'cust_int_max0'}, inplace=True)\n",
    "            \n",
    "            cust_int_std0 = smooth_stat(train_data, [\"CustomerIdx\"], type_of_stat='std',\n",
    "                                        target_feature='CustomerInterest', alpha=10)\n",
    "            cust_int_std0.rename(columns={f'{target_feature}': 'cust_int_std0'}, inplace=True)\n",
    "            \n",
    "            cust_int0 = cust_int_mean0.copy()\n",
    "            cust_int0 = cust_int0.merge(cust_int_min0, how = \"left\", on = \"CustomerIdx\")\n",
    "            cust_int0 = cust_int0.merge(cust_int_max0,   how = \"left\", on = \"CustomerIdx\")\n",
    "            cust_int0 = cust_int0.merge(cust_int_std0,   how = \"left\", on = \"CustomerIdx\")\n",
    "            \n",
    "            \n",
    "            # merge features\n",
    "            train_data = train_data.merge(cust_int0, how = \"left\", on = \"CustomerIdx\")\n",
    "            val_data = val_data.merge(cust_int0, how = \"left\", on = \"CustomerIdx\")\n",
    "            \n",
    "            train_data.fillna(0, inplace=True)\n",
    "            val_data.fillna(0, inplace=True)\n",
    "            \n",
    "            train_x = train_data.drop('CustomerInterest', axis=1)\n",
    "            train_y = train_data['CustomerInterest']\n",
    "            val_x = val_data.drop('CustomerInterest', axis=1)\n",
    "            val_y = val_data['CustomerInterest']\n",
    "            \n",
    "        \n",
    "            ##### END OF EXAMPLE\n",
    "            global features\n",
    "            # TRAINING\n",
    "            fold_model, fold_iter, fold_auc = _train_model(model, train_x[features], train_y, val_x[features], val_y)\n",
    "            \n",
    "            epochs[fold_id] = fold_iter    \n",
    "            aucs[fold_id] = fold_auc\n",
    "            feat[fold_id] = cust_int0\n",
    "            models[fold_id] = fold_model\n",
    "            \n",
    "            print(f'_______________________ \\n {fold_id} {fold_auc} \\n ____________________')\n",
    "            \n",
    "    return (models, epochs, aucs, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_mean(aucs):\n",
    "    train_auc = []\n",
    "    valid0_auc = []\n",
    "    test_auc = []\n",
    "    for fold in aucs:\n",
    "        train_auc.append(aucs[fold]['training']['auc'])  \n",
    "        test_auc.append(aucs[fold]['valid_1']['auc'])   \n",
    "    mean_train = np.asarray(train_auc).mean()\n",
    "    mean_test = np.asarray(test_auc).mean()\n",
    "    return({'train_auc':mean_train, 'cv_auc':mean_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttraining's auc: 0.914053\tvalid_1's auc: 0.860687\n",
      "[20]\ttraining's auc: 0.913486\tvalid_1's auc: 0.860046\n",
      "[30]\ttraining's auc: 0.913947\tvalid_1's auc: 0.860676\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.914571\tvalid_1's auc: 0.861813\n",
      "_______________________ \n",
      " 0 defaultdict(<class 'dict'>, {'training': {'auc': 0.91457144114848721}, 'valid_1': {'auc': 0.86181272183258706}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttraining's auc: 0.916946\tvalid_1's auc: 0.862888\n",
      "[20]\ttraining's auc: 0.916617\tvalid_1's auc: 0.862586\n",
      "[30]\ttraining's auc: 0.916874\tvalid_1's auc: 0.862916\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.917628\tvalid_1's auc: 0.864357\n",
      "_______________________ \n",
      " 1 defaultdict(<class 'dict'>, {'training': {'auc': 0.91762788288987063}, 'valid_1': {'auc': 0.86435669241939372}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttraining's auc: 0.909012\tvalid_1's auc: 0.871757\n",
      "[20]\ttraining's auc: 0.907144\tvalid_1's auc: 0.869868\n",
      "[30]\ttraining's auc: 0.908644\tvalid_1's auc: 0.871668\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.910601\tvalid_1's auc: 0.874128\n",
      "_______________________ \n",
      " 2 defaultdict(<class 'dict'>, {'training': {'auc': 0.9106013233605611}, 'valid_1': {'auc': 0.87412833823668379}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttraining's auc: 0.923537\tvalid_1's auc: 0.864237\n",
      "[20]\ttraining's auc: 0.922311\tvalid_1's auc: 0.862292\n",
      "[30]\ttraining's auc: 0.923729\tvalid_1's auc: 0.864981\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.925157\tvalid_1's auc: 0.869343\n",
      "_______________________ \n",
      " 3 defaultdict(<class 'dict'>, {'training': {'auc': 0.9251570125305244}, 'valid_1': {'auc': 0.86934280300943778}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[10]\ttraining's auc: 0.915107\tvalid_1's auc: 0.843307\n",
      "[20]\ttraining's auc: 0.914288\tvalid_1's auc: 0.842626\n",
      "[30]\ttraining's auc: 0.914591\tvalid_1's auc: 0.8443\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.915589\tvalid_1's auc: 0.841894\n",
      "_______________________ \n",
      " 4 defaultdict(<class 'dict'>, {'training': {'auc': 0.91558939612986712}, 'valid_1': {'auc': 0.8418941148431025}}) \n",
      " ____________________\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "#X = d_train.sort_values(by=['TradeDateKey'])[['NotionalEUR']]\n",
    "#y = d_train.sort_values(by=['TradeDateKey'])['CustomerInterest']\n",
    "\n",
    "d_train = d_train.sort_values(by=['TradeDateKey'])\n",
    "models, epochs, aucs, features_cv = train_fold(train, d_valid, n_folds, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_auc': 0.86230693406824099, 'train_auc': 0.91670941121186211}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "validation_path = \"../submissions/cv_validations/\"\n",
    "\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "\n",
    "# predict\n",
    "for i, model in enumerate(models):   \n",
    "    test_t = test.merge(features_cv[i], how = \"left\", on = \"CustomerIdx\")\n",
    "    test_t[\"CustomerInterest\"] = models[model].predict_proba(test_t[features], num_iteration = epochs[model])[:, 1]\n",
    "    # smart impute \n",
    "    test_t[test_t[features].isnull()][\"CustomerInterest\"] = 0\n",
    "    # export CSV\n",
    "    subm = test_t[[\"PredictionIdx\", \"CustomerInterest\"]]\n",
    "    subm.to_csv(f\"{validation_path}/submission{i}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = pd.read_csv(f\"{validation_path}/submission0.csv\")\n",
    "for sub in range(n_folds):\n",
    "    if(sub==0):\n",
    "        continue\n",
    "    else:\n",
    "        final_sub['CustomerInterest'] += pd.read_csv(f\"{validation_path}/submission{sub}.csv\")[\"CustomerInterest\"]\n",
    "final_sub['CustomerInterest'] /= n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub.to_csv(\"../submissions/cv_light_gbm_edited_the_cv.csv\", index=False, float_format = \"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
