{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import scipy.stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA PARTITIONING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(\"../data/raw/Trade.csv\")\n",
    "test  = pd.read_csv(\"../data/raw/Challenge_20180423.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target variable\n",
    "train[\"CustomerInterest\"] = 1\n",
    "train[\"CustomerInterest\"][train[\"TradeStatus\"] == \"Holding\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "'''d_stats = train[(train[\"TradeDateKey\"] <   20170323)]\n",
    "d_train = train[(train[\"TradeDateKey\"] >=  20170323) & (train[\"TradeDateKey\"] < 20180323)]\n",
    "d_valid = train[(train[\"TradeDateKey\"] >=  20180323)]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CROSS-VALIDATION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# learner settings\n",
    "metric   = \"auc\"\n",
    "verbose  = 10\n",
    "stopping = 10\n",
    "seed = 42\n",
    "features = ['cust_mean']\n",
    "n_folds = 5\n",
    "\n",
    "# lgb settings\n",
    "gbm = lgb.LGBMClassifier(n_estimators     = 1000,\n",
    "                         learning_rate    = 0.005,\n",
    "                         num_leaves       = 70,\n",
    "                         colsample_bytree = 0.8,\n",
    "                         subsample        = 0.9,\n",
    "                         max_depth        = 7,\n",
    "                         reg_alpha        = 0.1,\n",
    "                         reg_lambda       = 0.1,\n",
    "                         min_split_gain   = 0.01,\n",
    "                         min_child_weight = 2,\n",
    "                         random_state     = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_model(model, train_x, train_y, val_x, val_y):\n",
    "    #create features inside the CV\n",
    "    \n",
    "    # train lightGBM\n",
    "    global verbose\n",
    "    global stopping\n",
    "    global metric\n",
    "    model = model.fit(train_x, train_y, \n",
    "              eval_set = [(train_x, train_y), (val_x, val_y)], \n",
    "              eval_metric = metric, \n",
    "              verbose = verbose, \n",
    "              early_stopping_rounds = stopping)\n",
    "    \n",
    "    # save number of iterations\n",
    "    num_iters = gbm.best_iteration_\n",
    "    best_auc = gbm.best_score_\n",
    "    return (model, num_iters, best_auc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fold(dataset, fold_count, model):\n",
    "    ''' Please, use Xs and y_s sorted by date,\n",
    "    otherwise it can overfitting by looking in the future'''\n",
    "    fold_size = len(dataset) // fold_count\n",
    "    models = {}\n",
    "    epochs = {}\n",
    "    aucs = {}\n",
    "    feat = {}\n",
    "    for fold_id in range(0, fold_count):\n",
    "            fold_start = fold_size * fold_id\n",
    "            fold_end = fold_start + fold_size\n",
    "            if fold_id == fold_size - 1:\n",
    "                fold_end = len(dataset)\n",
    "                \n",
    "            train_data = pd.concat([dataset.iloc[:fold_start,:], dataset.iloc[fold_end:,:]])\n",
    "            val_data = dataset.iloc[fold_start:fold_end,:]\n",
    "           # train_x = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "           # train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "           # val_x = X[fold_start:fold_end]\n",
    "           # val_y = y[fold_start:fold_end]\n",
    "\n",
    "            # FEATURE CREATION GOES HERE\n",
    "            # Example (in general can be imporved)\n",
    "\n",
    "            # compute historical target ratio\n",
    "            cust_int = train_data\n",
    "            cust_int = cust_int[[\"CustomerIdx\", \"CustomerInterest\", \"IsinIdx\", \"BuySell\"]]\n",
    "            cust_int = cust_int.groupby([\"CustomerIdx\", \"IsinIdx\", \"BuySell\"], as_index = False).mean()\n",
    "            cust_int.rename(columns={'CustomerInterest':'cust_mean'}, inplace=True)\n",
    "\n",
    "            \n",
    "            # merge features\n",
    "            train_data = train_data.merge(cust_int, how = \"left\", on = [\"CustomerIdx\", \"IsinIdx\", \"BuySell\"])\n",
    "            val_data = val_data.merge(cust_int, how = \"left\", on = [\"CustomerIdx\", \"IsinIdx\", \"BuySell\"])\n",
    "            \n",
    "            train_data['cust_mean'].fillna(0, inplace=True)\n",
    "            val_data['cust_mean'].fillna(0, inplace=True)\n",
    "            feat[fold_id] = cust_int\n",
    "            \n",
    "            train_x = train_data.drop('CustomerInterest', axis=1)\n",
    "            train_y = train_data['CustomerInterest']\n",
    "            val_x = val_data.drop('CustomerInterest', axis=1)\n",
    "            val_y = val_data['CustomerInterest']\n",
    "            \n",
    "        \n",
    "            ##### END OF EXAMPLE\n",
    "            global features\n",
    "            # TRAINING\n",
    "            fold_model, fold_iter, fold_auc = _train_model(model, train_x[features], train_y, val_x[features], val_y)\n",
    "            epochs[fold_id] = fold_iter    \n",
    "            aucs[fold_id] = fold_auc\n",
    "            print(f'_______________________ \\n {fold_id} {fold_auc} \\n ____________________')\n",
    "            models[fold_id] = fold_model\n",
    "    return (models, epochs, aucs, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_mean(aucs):\n",
    "    train_auc = []\n",
    "    valid0_auc = []\n",
    "    test_auc = []\n",
    "    for fold in aucs:\n",
    "        train_auc.append(aucs[fold]['training']['auc'])  \n",
    "        test_auc.append(aucs[fold]['valid_1']['auc'])   \n",
    "    mean_train = np.asarray(train_auc).mean()\n",
    "    mean_test = np.asarray(test_auc).mean()\n",
    "    return({'train_auc':mean_train, 'cv_auc':mean_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.98113\tvalid_1's auc: 0.694768\n",
      "[20]\ttraining's auc: 0.98113\tvalid_1's auc: 0.694768\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's auc: 0.98113\tvalid_1's auc: 0.694768\n",
      "_______________________ \n",
      " 0 defaultdict(<class 'dict'>, {'training': {'auc': 0.98112989902538716}, 'valid_1': {'auc': 0.69476849255861373}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.983122\tvalid_1's auc: 0.697308\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.983122\tvalid_1's auc: 0.697308\n",
      "_______________________ \n",
      " 1 defaultdict(<class 'dict'>, {'training': {'auc': 0.98312172562427924}, 'valid_1': {'auc': 0.69730847079194802}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.982192\tvalid_1's auc: 0.727155\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.982192\tvalid_1's auc: 0.727155\n",
      "_______________________ \n",
      " 2 defaultdict(<class 'dict'>, {'training': {'auc': 0.98219209412804775}, 'valid_1': {'auc': 0.72715542834348523}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.981715\tvalid_1's auc: 0.728495\n",
      "[20]\ttraining's auc: 0.981715\tvalid_1's auc: 0.728495\n",
      "[30]\ttraining's auc: 0.981715\tvalid_1's auc: 0.728495\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.981715\tvalid_1's auc: 0.728495\n",
      "_______________________ \n",
      " 3 defaultdict(<class 'dict'>, {'training': {'auc': 0.98171490667792494}, 'valid_1': {'auc': 0.7284953955489073}}) \n",
      " ____________________\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\ttraining's auc: 0.98145\tvalid_1's auc: 0.661378\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.98145\tvalid_1's auc: 0.661379\n",
      "_______________________ \n",
      " 4 defaultdict(<class 'dict'>, {'training': {'auc': 0.98144975961523728}, 'valid_1': {'auc': 0.66137864412189706}}) \n",
      " ____________________\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "#X = d_train.sort_values(by=['TradeDateKey'])[['NotionalEUR']]\n",
    "#y = d_train.sort_values(by=['TradeDateKey'])['CustomerInterest']\n",
    "\n",
    "train = train.sort_values(by=['TradeDateKey'])\n",
    "models, epochs, aucs, features_cv = train_fold(train, n_folds, gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_auc': 0.70182128627297025, 'train_auc': 0.98192167701417521}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "validation_path = \"../submissions/cv_validations/\"\n",
    "\n",
    "if not os.path.exists(validation_path):\n",
    "    os.makedirs(validation_path)\n",
    "\n",
    "# predict\n",
    "for i, model in enumerate(models):   \n",
    "    test_t = test.merge(features_cv[i], how = \"left\", on = [\"CustomerIdx\", \"IsinIdx\", \"BuySell\"])\n",
    "    test_t[\"CustomerInterest\"] = models[model].predict_proba(test_t[features], num_iteration = epochs[model])[:, 1]\n",
    "    # smart impute \n",
    "    test_t[test_t[features].isnull()][\"CustomerInterest\"] = 0\n",
    "    # export CSV\n",
    "    subm = test_t[[\"PredictionIdx\", \"CustomerInterest\"]]\n",
    "    subm.to_csv(f\"{validation_path}/submission{i}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub = pd.read_csv(f\"{validation_path}/submission0.csv\")\n",
    "for sub in range(n_folds):\n",
    "    if(sub==0):\n",
    "        continue\n",
    "    else:\n",
    "        final_sub['CustomerInterest'] += pd.read_csv(f\"{validation_path}/submission{sub}.csv\")[\"CustomerInterest\"]\n",
    "final_sub['CustomerInterest'] /= n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub.to_csv(\"../submissions/cv_light_gbm.csv\", index=False, float_format = \"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
