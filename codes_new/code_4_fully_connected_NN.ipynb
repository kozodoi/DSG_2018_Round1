{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/prepared/data_basic.csv\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = list(enumerate([i for i in data.CustomerIdx.unique()]))\n",
    "bonds = list(enumerate([i for i in data.IsinIdx.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer2idx = {o:i for i,o in customers}\n",
    "bond2idx = {o:i for i,o in bonds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input sizes\n",
    "n_customer = data.CustomerIdx.nunique()\n",
    "n_bond = data.IsinIdx.nunique()\n",
    "#n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.CustomerInterest.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIdx = np.array(data.Week<116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_train = np.array([customer2idx[id] for id in data.CustomerIdx.loc[trainIdx]])\n",
    "bond_train = np.array([bond2idx[id] for id in data.IsinIdx.loc[trainIdx]])\n",
    "y_train = data.CustomerInterest[trainIdx]\n",
    "\n",
    "cust_test = np.array([customer2idx[id] for id in data.CustomerIdx.loc[~trainIdx]])\n",
    "bond_test = np.array([bond2idx[id] for id in data.IsinIdx.loc[~trainIdx]])\n",
    "y_test = data.CustomerInterest[~trainIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_class_weight(\"balanced\", classes=np.array([0,1]), y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import Input, Embedding, Dense, Dropout, concatenate, Flatten, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input layer with one row of IDs\n",
    "cust_in = Input(shape = (1,), dtype='int64', name = \"cust_in\")\n",
    "bond_in = Input(shape = (1,), dtype='int64', name = \"bond_in\")\n",
    "#features_in = Input(shape = (n_features,), name = \"features_in\")\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "# These will be optimized\n",
    "# A regulariztaion is added to avoid very large weights\n",
    "cust = Embedding(n_customer, 25, input_length=1, embeddings_regularizer=l2(1e-5))(cust_in)\n",
    "bond = Embedding(n_bond, 25, input_length=1, embeddings_regularizer=l2(1e-5))(bond_in)\n",
    "\n",
    "# Build NN from embeddings and other features\n",
    "x = concatenate([cust, bond]) #, features_in])\n",
    "x = Flatten()(x)\n",
    "x= Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(Dense(32, activation='relu')(x))\n",
    "out = Dense(1, activation = \"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we specify the model that we want to use\n",
    "model = Model([cust_in, bond_in], out) # \n",
    "model.compile(Adam(0.01), loss=\"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([cust_train, bond_train], y_train,  #\n",
    "          validation_data = ([cust_test, bond_test], y_test),\n",
    "          class_weight={0:0.53647409, 1:7.35417975},\n",
    "          batch_size = 50000, epochs = 5\n",
    "    #,callbacks = keras.callbacks.ModelCheckpoint('../models/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict([cust_test, bond_test], batch_size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test, y_score=pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
