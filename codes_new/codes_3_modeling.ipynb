{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "data = pd.read_csv(\"../data/prepared/data_v2_0_100.csv\", compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "print(\"Dimensions:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PREPARATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check NA\n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features\n",
    "excluded_features = [\"PredictionIdx\", \"CustomerIdx\", \"IsinIdx\", \"BuySell\", \"Week\", \"CustomerInterest\"]\n",
    "features = [var for var in data.columns if var not in excluded_features]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop high recency\n",
    "\n",
    "# drop from train only\n",
    "data = data[(data.Week == 121) | (data.Recency1 < data.Recency1.max())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data partitioning\n",
    "\n",
    "# training\n",
    "X_train = data.loc[data.Week < 120, features]\n",
    "y_train = data.loc[data.Week < 120].CustomerInterest\n",
    "\n",
    "# validation\n",
    "X_valid = data.loc[data.Week == 120, features]\n",
    "y_valid = data.loc[data.Week == 120].CustomerInterest\n",
    "\n",
    "# test set\n",
    "test = data.loc[data.Week == 121]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MODELING - STAGE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparations\n",
    "#losses = []\n",
    "#costs = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modeling loop\n",
    "#for c in costs:\n",
    "#    print(f'Training for c = {c}...')\n",
    "#    lr = LogisticRegression(C = c)\n",
    "#    lr = lr.fit(X_train, y_train)\n",
    "#    probs = lr.predict_proba(X_valid)[:,1]\n",
    "#    loss = roc_auc_score(y_valid, probs)\n",
    "#    print(f'- AUC for c = {c} = {loss}')\n",
    "#    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the best C\n",
    "#cost = costs[np.argmax(losses)]\n",
    "#print(\"Best C =\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# parallel settings\n",
    "cores = 16\n",
    "\n",
    "# learner settings\n",
    "metric   = \"auc\"\n",
    "verbose  = 10\n",
    "stopping = 30\n",
    "\n",
    "# lightGBM\n",
    "gbm = lgb.LGBMClassifier(n_estimators     = 500,\n",
    "                         learning_rate    = 0.005,\n",
    "                         num_leaves       = 70,\n",
    "                         colsample_bytree = 0.8,\n",
    "                         subsample        = 0.9,\n",
    "                         max_depth        = 7,\n",
    "                         reg_alpha        = 0.1,\n",
    "                         reg_alambda       = 0.1,\n",
    "                         min_split_gain   = 0.01,\n",
    "                         min_child_weight = 2,\n",
    "                         random_state     = 42,\n",
    "                         num_threads      = cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train lightGBM\n",
    "gbm = gbm.fit(X_train, y_train, \n",
    "              eval_set = [(X_train, y_train), (X_valid, y_valid)], \n",
    "              eval_metric = metric, verbose = verbose, \n",
    "              early_stopping_rounds = stopping)\n",
    "    \n",
    "# save number of iterations\n",
    "num_iters = gbm.best_iteration_  \n",
    "\n",
    "### RESULTS\n",
    "# k = 8,  train = last 20 weeks, drop 80 weeks, only recency & frequency:           0.780024 (0.75749 LB)\n",
    "# k = 57, train = last 20 weeks, drop 80 weeks, added dummies & bond data:          0.782063 (0.76356 LB)\n",
    "# k = 59, train = last 20 weeks, drop 80 weeks, additional recency and frequency:   0.781909 ()\n",
    "# k = 57, train = last 20 weeks, drop 30 weeks, added 50 weeks for RF computation:  0.815764 ()\n",
    "# k = 59, train = last 20 weeks, drop 30 weeks, more weeks and 6 RF features:       0.817509 (0.77096 LB)\n",
    "# k = 59, train = last 20 weeks, drop 0 weeks, no new features:                     0.832469 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### VARIABLE IMPORTANCE\n",
    "\n",
    "# load variable importance\n",
    "importance = pd.DataFrame()\n",
    "importance[\"feature\"] = features\n",
    "importance[\"importance\"] = gbm.feature_importances_\n",
    "\n",
    "# plot variable importance\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.barplot(x = \"importance\", y = \"feature\", data = importance.sort_values(by = \"importance\", ascending = False))\n",
    "plt.title('LGBM Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../var_importance.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MODELING - STAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use full data as train\n",
    "X_train = data.loc[data.Week <= 120, features]\n",
    "y_train = data.loc[data.Week <= 120].CustomerInterest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain model with the best C\n",
    "#print(f'Training for c = {cost}...')\n",
    "#lr = LogisticRegression(C = cost)\n",
    "#lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "#test[\"CustomerInterestLOG\"] = lr.predict_proba(test[features])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### retrain model with the best iters\n",
    "\n",
    "# lightGBM\n",
    "gbm = lgb.LGBMClassifier(n_estimators     = num_iters,\n",
    "                         learning_rate    = 0.005,\n",
    "                         num_leaves       = 70,\n",
    "                         colsample_bytree = 0.8,\n",
    "                         subsample        = 0.9,\n",
    "                         max_depth        = 7,\n",
    "                         reg_alpha        = 0.1,\n",
    "                         reg_alambda      = 0.1,\n",
    "                         min_split_gain   = 0.01,\n",
    "                         min_child_weight = 2,\n",
    "                         random_state     = 42,\n",
    "                         num_threads      = cores)\n",
    "\n",
    "# train lightGBM\n",
    "gbm = gbm.fit(X_train, y_train, \n",
    "              eval_set = [(X_train, y_train)], \n",
    "              eval_metric = metric, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "test[\"CustomerInterestLGB\"] = gbm.predict_proba(test[features], num_iteration = num_iters)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check rank correlation with the best submission\n",
    "from scipy.stats import spearmanr\n",
    "best = pd.read_csv(\"../submissions/data_v2_30_lgb_val08175.csv\")\n",
    "spearmanr(test[\"CustomerInterestLGB\"], best.CustomerInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CSV\n",
    "subm = test[[\"PredictionIdx\", \"CustomerInterestLGB\"]]\n",
    "subm.columns =[\"PredictionIdx\", \"CustomerInterest\"]\n",
    "subm.to_csv(\"../submissions/data_v2_0_100_lgb_val0832469.csv\", index = False, float_format = \"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
